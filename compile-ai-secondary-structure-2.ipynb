{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-02T01:52:25.459154Z","iopub.execute_input":"2023-10-02T01:52:25.459524Z","iopub.status.idle":"2023-10-02T01:52:25.469938Z","shell.execute_reply.started":"2023-10-02T01:52:25.459496Z","shell.execute_reply":"2023-10-02T01:52:25.468629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndf = pd.read_csv('/kaggle/input/protein-secondary-structure/2018-06-06-ss.cleaned.csv')\nprint(df.shape)\n\ndef seq2ngrams(seqs, n=3):\n    return np.array([[seq[i:i+n] for i in range(len(seq))] for seq in seqs])\n\ndf = df.head(5001)\nmaxlen_seq = 500\ninput_seqs, target_seqs = df[['seq', 'sst3']][(df.len <= maxlen_seq) & (~df.has_nonstd_aa)].values.T\ninput_grams = seq2ngrams(input_seqs)\nprint(len(input_seqs))","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:52:25.509329Z","iopub.execute_input":"2023-10-02T01:52:25.510068Z","iopub.status.idle":"2023-10-02T01:52:56.163610Z","shell.execute_reply.started":"2023-10-02T01:52:25.510034Z","shell.execute_reply":"2023-10-02T01:52:56.162133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf.len.hist(bins=100)\nprint(df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:52:56.165591Z","iopub.execute_input":"2023-10-02T01:52:56.165926Z","iopub.status.idle":"2023-10-02T01:52:56.623603Z","shell.execute_reply.started":"2023-10-02T01:52:56.165895Z","shell.execute_reply":"2023-10-02T01:52:56.622335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\n# show proportion of each amino acid in a table\nAA_counts = {'ss_2018': defaultdict(lambda: 0)}\n# count the types for each dataset\nfor (seq, nonstd) in zip(df['seq'], df['has_nonstd_aa']):\n    if not nonstd:\n        for aa in set(seq):\n            if aa != '*':\n                AA_counts['ss_2018'][aa] += seq.count(aa)\n\n# order the amino acids by decreasing total abundance\ntotal_aa = [sum([AA_counts[d][aa] for d in AA_counts.keys()]) for aa in AA_counts['ss_2018'].keys() ]\ntemp = sorted(total_aa, reverse = True)    \norder = [total_aa.index(v) for v in temp]\naa_order = [list(AA_counts['ss_2018'].keys())[i] for i in order]\ntbl_data = {'Amino Acid': aa_order,\n            'ss_2018': [ round(AA_counts['ss_2018'][aa] / sum(AA_counts['ss_2018'].values()), 3) for aa in aa_order]}\npd.DataFrame(tbl_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:52:56.625484Z","iopub.execute_input":"2023-10-02T01:52:56.625952Z","iopub.status.idle":"2023-10-02T01:52:56.661804Z","shell.execute_reply.started":"2023-10-02T01:52:56.625909Z","shell.execute_reply":"2023-10-02T01:52:56.660432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\ndict_a = {'C':[],'H':[],'E':[]}\ndict_f = {'C':[],'H':[],'E':[]}\ndict_p = {'C':[],'H':[],'E':[]}\ndict_s = {'C':[],'H':[],'E':[]}\n\nfor se,sst in zip(df['seq'],df['sst3']):\n    for s,ss in zip(se,sst):\n        if s == 'A':\n            if ss == 'C': dict_a['C'].append(1)\n            elif ss == 'H': dict_a['H'].append(1)\n            elif ss == 'E': dict_a['E'].append(1)\n        elif s == 'F':        \n            if ss == 'C': dict_f['C'].append(1)\n            elif ss == 'H': dict_f['H'].append(1)\n            elif ss == 'E': dict_f['E'].append(1)\n        elif s == 'P':        \n            if ss == 'C': dict_p['C'].append(1)\n            elif ss == 'H': dict_p['H'].append(1)\n            elif ss == 'E': dict_p['E'].append(1)\n        elif s == 'S':        \n            if ss == 'C': dict_s['C'].append(1)\n            elif ss == 'H': dict_s['H'].append(1)\n            elif ss == 'E': dict_s['E'].append(1)\n                \n                \nfor k in dict_a.keys(): dict_a[k] = sum(dict_a[k])\nfor k in dict_f.keys(): dict_f[k] = sum(dict_f[k])\nfor k in dict_p.keys(): dict_p[k] = sum(dict_p[k])\nfor k in dict_s.keys(): dict_s[k] = sum(dict_s[k])\nprint('dict_a:  ',dict_a)\nprint('dict_f:  ',dict_f)\nprint('dict_p:  ',dict_p)\nprint('dict_s:  ',dict_s)\n\nplt.figure(figsize=(14,4));\nplt.subplot(1,2,1);\nsns.barplot(x=list(dict_a.keys()),y=list(dict_a.values()),color='gray');\nplt.title('Secondary Structure character counts for aminoacid A');\nplt.subplot(1,2,2);\nsns.barplot(x=list(dict_f.keys()),y=list(dict_f.values()),color='gray');\nplt.title('Secondary Structure character counts for aminoacid F');\nplt.figure(figsize=(14,4));\nplt.subplot(1,2,1);\nsns.barplot(x=list(dict_p.keys()),y=list(dict_p.values()),color='gray');\nplt.title('Secondary Structure character counts for aminoacid P');\nplt.subplot(1,2,2);\nsns.barplot(x=list(dict_s.keys()),y=list(dict_s.values()),color='gray');\nplt.title('Secondary Structure character counts for aminoacid S');","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:52:56.664327Z","iopub.execute_input":"2023-10-02T01:52:56.665399Z","iopub.status.idle":"2023-10-02T01:52:58.280021Z","shell.execute_reply.started":"2023-10-02T01:52:56.665363Z","shell.execute_reply":"2023-10-02T01:52:58.278645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bi-LSTM to predict secondary structure","metadata":{}},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"def seq2ngrams(seqs, n=3):\n    return np.array([[seq[i:i+n] for i in range(len(seq))] for seq in seqs])\n\nmaxlen_seq = 500\ninput_seqs, target_seqs = df[['seq', 'sst3']][(df.len <= maxlen_seq) & (~df.has_nonstd_aa)].values.T\ninput_grams = seq2ngrams(input_seqs)\nprint(len(input_seqs))","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:52:58.282204Z","iopub.execute_input":"2023-10-02T01:52:58.282895Z","iopub.status.idle":"2023-10-02T01:53:00.494162Z","shell.execute_reply.started":"2023-10-02T01:52:58.282791Z","shell.execute_reply":"2023-10-02T01:53:00.493015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing import text\nfrom keras.utils.data_utils import pad_sequences \nfrom keras.preprocessing.text import Tokenizer\nfrom keras.utils import to_categorical\n\ntokenizer_encoder = Tokenizer()\ntokenizer_encoder.fit_on_texts(input_grams)\ninput_data = tokenizer_encoder.texts_to_sequences(input_grams)\ninput_data = pad_sequences(input_data, maxlen=maxlen_seq, padding='post')\n\ntokenizer_decoder = Tokenizer(char_level=True)\ntokenizer_decoder.fit_on_texts(target_seqs)\ntarget_data = tokenizer_decoder.texts_to_sequences(target_seqs)\ntarget_data = pad_sequences(target_data, maxlen=maxlen_seq, padding='post')\ntarget_data = to_categorical(target_data)\ninput_data.shape, target_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:53:00.495989Z","iopub.execute_input":"2023-10-02T01:53:00.496686Z","iopub.status.idle":"2023-10-02T01:53:09.876449Z","shell.execute_reply.started":"2023-10-02T01:53:00.496641Z","shell.execute_reply":"2023-10-02T01:53:09.875035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building model","metadata":{}},{"cell_type":"code","source":"from keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom keras.layers import LSTM, Embedding, Dense, TimeDistributed, Bidirectional\n\nn_words = len(tokenizer_encoder.word_index) + 1\nn_tags = len(tokenizer_decoder.word_index) + 1\nprint(n_words, n_tags)\n\ninput = Input(shape=(maxlen_seq))\nx = Embedding(input_dim=n_words, output_dim=128, input_length=maxlen_seq)(input)\nx = Bidirectional(LSTM(units=64, return_sequences=True, recurrent_dropout=0.1))(x)\ny = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(x)\nmodel = Model(input, y)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:53:09.878541Z","iopub.execute_input":"2023-10-02T01:53:09.879799Z","iopub.status.idle":"2023-10-02T01:53:10.948256Z","shell.execute_reply.started":"2023-10-02T01:53:09.879753Z","shell.execute_reply":"2023-10-02T01:53:10.946939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train and Evaluate Model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom keras.metrics import categorical_accuracy\nfrom keras import backend  as K\nimport tensorflow as tf\n\ndef q3_acc(y_true, y_pred):\n    y = tf.argmax(y_true, axis=-1)\n    y_ = tf.argmax(y_pred, axis=-1)\n    mask = tf.greater(y, 0)\n    return K.cast(K.equal(tf.boolean_mask(y, mask), tf.boolean_mask(y_, mask)), K.floatx())\n\nmodel.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", q3_acc])\n\nX_train, X_test, y_train, y_test = train_test_split(input_data, target_data, test_size=.4, random_state=0)\nseq_train, seq_test, target_train, target_test = train_test_split(input_seqs, target_seqs, test_size=.4, random_state=0)\n\nhistory = model.fit(X_train, y_train, batch_size=128, epochs=20, validation_data=(X_test, y_test), verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:53:10.950029Z","iopub.execute_input":"2023-10-02T01:53:10.950432Z","iopub.status.idle":"2023-10-02T01:58:08.484898Z","shell.execute_reply.started":"2023-10-02T01:53:10.950400Z","shell.execute_reply":"2023-10-02T01:58:08.483698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Plot training history\ndef viz_hist(history):\n    plt.figure(figsize=(12, 6))\n\n    # Plot training & validation loss values\n    plt.subplot(1, 3, 1)\n    plt.plot(history.history['loss'], label='Training Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Model Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    # Plot training & validation accuracy values\n    plt.subplot(1, 3, 2)\n    plt.plot(history.history['accuracy'], label='Training Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.title('Model Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    # Plot training & validation accuracy values\n    plt.subplot(1, 3, 3)\n    plt.plot(history.history['q3_acc'], label='Training Q3 Accuracy')\n    plt.plot(history.history['val_q3_acc'], label='Validation Q3 Accuracy')\n    plt.title('Model Q3 Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.show()\n    \nviz_hist(history)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:08.486830Z","iopub.execute_input":"2023-10-02T01:58:08.488011Z","iopub.status.idle":"2023-10-02T01:58:09.227031Z","shell.execute_reply.started":"2023-10-02T01:58:08.487963Z","shell.execute_reply":"2023-10-02T01:58:09.225929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def onehot_to_seq(oh_seq, index):\n    s = ''\n    for o in oh_seq:\n        i = np.argmax(o)\n        if i != 0:\n            s += index[i]\n        else:\n            break\n    return s\n\ndef plot_results(x, y, y_):\n    print(\"---\")\n    print(\"Input: \" + str(x))\n    print(\"Target: \" + str(onehot_to_seq(y, revsere_decoder_index).upper()))\n    print(\"Result: \" + str(onehot_to_seq(y_, revsere_decoder_index).upper()))\n    fig = plt.figure(figsize=(10,2))\n    plt.imshow(y.T, cmap='Blues')\n    plt.imshow(y_.T, cmap='Reds', alpha=.5)\n    plt.yticks(range(4), [' '] + [revsere_decoder_index[i+1].upper() for i in range(3)])\n    plt.show()\n    \nrevsere_decoder_index = {value:key for key,value in tokenizer_decoder.word_index.items()}\nrevsere_encoder_index = {value:key for key,value in tokenizer_encoder.word_index.items()}\n\nN=3\ny_train_pred = model.predict(X_train[:N])\ny_test_pred = model.predict(X_test[:N])\nprint('training')\nfor i in range(N):\n    plot_results(seq_train[i], y_train[i], y_train_pred[i])\nprint('testing')\nfor i in range(N):\n    plot_results(seq_test[i], y_test[i], y_test_pred[i])","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:09.231236Z","iopub.execute_input":"2023-10-02T01:58:09.231529Z","iopub.status.idle":"2023-10-02T01:58:11.131820Z","shell.execute_reply.started":"2023-10-02T01:58:09.231504Z","shell.execute_reply":"2023-10-02T01:58:11.130356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Optimizing Hyperparameter","metadata":{}},{"cell_type":"code","source":"!pip install optuna","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:11.133222Z","iopub.execute_input":"2023-10-02T01:58:11.133536Z","iopub.status.idle":"2023-10-02T01:58:23.558359Z","shell.execute_reply.started":"2023-10-02T01:58:11.133510Z","shell.execute_reply":"2023-10-02T01:58:23.556161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    # Get the hyperparameters\n    dropout = trial.suggest_float('dropout', 0.1, 0.2)\n    activation = trial.suggest_categorical('activation', ['relu', 'tanh', 'softmax'])\n\n    # Create the BiLSTM model\n    input = Input(shape=(maxlen_seq))\n    x = Embedding(input_dim=n_words, output_dim=128, input_length=maxlen_seq)(input)\n    x = Bidirectional(LSTM(units=64, return_sequences=True, recurrent_dropout=dropout))(x)\n    y = TimeDistributed(Dense(n_tags, activation=activation))(x)\n    model = Model(input, y)\n    \n    # Compile the model\n    model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", q3_acc])\n\n\n    # Train the model\n    history = model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_test, y_test), verbose=1)\n    #viz \n    viz_hist(history)\n#     y_res = model.predict(X_test)\n#     return q3_acc(y_test,y_res)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T03:22:21.644144Z","iopub.execute_input":"2023-10-02T03:22:21.644565Z","iopub.status.idle":"2023-10-02T03:22:21.654248Z","shell.execute_reply.started":"2023-10-02T03:22:21.644521Z","shell.execute_reply":"2023-10-02T03:22:21.652822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=10)\n# best_dropout = study.best_params['dropout']\n# best_activation = study.best_params['activation']","metadata":{"execution":{"iopub.status.busy":"2023-10-02T03:22:26.156184Z","iopub.execute_input":"2023-10-02T03:22:26.156821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ML to predict secondary structure","metadata":{}},{"cell_type":"code","source":"import numpy as np                                     # linear algebra\nimport pandas as pd                                    # data processing, CSV file I/O (e.g. pd.read_csv)\nimport copy                                            #to copy list\nfrom sklearn.model_selection import train_test_split   #to split dataset into train and test set\nfrom sklearn.svm import SVC                            #to create svc instance\nfrom sklearn.metrics import classification_report      #to create report for precision,recall,f1-score,accuracy\nfrom sklearn import metrics                            #to get accuracy\nfrom sklearn.model_selection import GridSearchCV       #to optimise the hyper-parameter\nimport math","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.531233Z","iopub.status.idle":"2023-10-02T01:58:25.531645Z","shell.execute_reply.started":"2023-10-02T01:58:25.531452Z","shell.execute_reply":"2023-10-02T01:58:25.531470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pre processing","metadata":{}},{"cell_type":"code","source":"#dataset 1\nmaxlen_seq = 128\ninput_seqs, target_seqs = df[['seq', 'sst3']][(df.len <= maxlen_seq) & (~df.has_nonstd_aa)].values.T\ninput_seqs, target_seqs = df[['seq', 'sst3']][(~df.has_nonstd_aa)].values.T\n# input_grams = seq2ngrams(input_seqs)\nprint(input_seqs[0:5])","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.535591Z","iopub.status.idle":"2023-10-02T01:58:25.536073Z","shell.execute_reply.started":"2023-10-02T01:58:25.535807Z","shell.execute_reply":"2023-10-02T01:58:25.535822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputSeqs=[]\ntargetSeqs=[]\nfor i in range(input_seqs.size):\n    j=0\n    while(j<len(input_seqs[i])/128):\n        start = j*128\n        end = start+128\n        inputSeqs.append(input_seqs[i][start:end])\n        targetSeqs.append(target_seqs[i][start:end])\n        j+=1\n        \nprint(len(targetSeqs))\nprint(len(inputSeqs))","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.537721Z","iopub.status.idle":"2023-10-02T01:58:25.538496Z","shell.execute_reply.started":"2023-10-02T01:58:25.538240Z","shell.execute_reply":"2023-10-02T01:58:25.538266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Looking for incomplete data**","metadata":{}},{"cell_type":"code","source":"for row in range(len(targetSeqs)):\n    secondary_lenth = len(targetSeqs[row])\n    primary_lenth = len(inputSeqs[row])\n    \n    if(secondary_lenth != primary_lenth):\n        print(\"(\",row,\") Secondary_Structure ->\", targetSeqs[row],\" Primary_Structure -> \",inputSeqs[row])\n    \nprint(len(inputSeqs))","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.539655Z","iopub.status.idle":"2023-10-02T01:58:25.540311Z","shell.execute_reply.started":"2023-10-02T01:58:25.540095Z","shell.execute_reply":"2023-10-02T01:58:25.540118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"secondary_count = 0\nprimary_count = 0\ndataCheck = \"ACEDGFIHKMLNQPSRTWVY\"\nindex=[]\nfor row in range(len(targetSeqs)):\n    secondary_lenth = len(targetSeqs[row])\n    primary_lenth = len(inputSeqs[row])\n    secondary_count = secondary_count + secondary_lenth\n    primary_count = primary_count + primary_lenth\n    if(secondary_lenth != primary_lenth):\n        print(\"(\",row,\") Secondary_Structure ->\", targetSeqs[row],\" Primary_Structure -> \",inputSeqs[row])\n    for col in range(len(inputSeqs[row])):\n        #print(\"before :\",inputSeqs[row][col])\n        if len(inputSeqs[row])<2:\n            index.append(row)\n        if dataCheck.find(inputSeqs[row][col])==-1:\n            #print(\"after :\",inputSeqs[row][col])\n            index.append(row)\n           # print(\"Row : \"+str(row)+\"have been deleted for having unknown data\")\n            break\n            \n\ninputSeqs =np.delete(inputSeqs,index)\ntargetSeqs =np.delete(targetSeqs,index)\n        \nprint(\"count of secondary structure : \",secondary_count)\nprint(\"count of primary structure : \",primary_count)\nprint(\"size of primary structure : \",len(inputSeqs))","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.541320Z","iopub.status.idle":"2023-10-02T01:58:25.541957Z","shell.execute_reply.started":"2023-10-02T01:58:25.541709Z","shell.execute_reply":"2023-10-02T01:58:25.541730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Orthogonal Encoding - Target Labeling**","metadata":{}},{"cell_type":"code","source":"def split(sequence): \n    return [char for char in sequence]","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.543185Z","iopub.status.idle":"2023-10-02T01:58:25.543897Z","shell.execute_reply.started":"2023-10-02T01:58:25.543620Z","shell.execute_reply":"2023-10-02T01:58:25.543655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"primary_split = []\nsecondary_split = []\nfor row in range(int(len(targetSeqs)/1)):\n    primary_split.append(split(inputSeqs[row]))\n    secondary_split.append(split(targetSeqs[row]))\n    \nprint(len(primary_split))","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.544928Z","iopub.status.idle":"2023-10-02T01:58:25.545530Z","shell.execute_reply.started":"2023-10-02T01:58:25.545329Z","shell.execute_reply":"2023-10-02T01:58:25.545351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The results of the split primary and secondary structure of the protein are then converted into orthogonal encoding and target labeling. A switch case snippet for each amino acid in the primary structure of a protein as follows .<br>\nSecondary structure character represent ->\n1. H= α-helix\n2. C= Loops and irregular elements\n3. E= β-strand\n4. B= β-bridge\n5. G= 3-helix\n6. I= π-helix\n7. T= Turn\n8. S= Bend","metadata":{}},{"cell_type":"code","source":"def orthogonal_primary(arg):\n    switch = {\n        'A' : np.array([1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]),  # 20 amino acids\n        'C' : np.array([0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]),\n        'E' : np.array([0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]),\n        'D' : np.array([0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]),\n        'G' : np.array([0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]),\n        'F' : np.array([0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]),\n        'I' : np.array([0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0]),\n        'H' : np.array([0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0]),\n        'K' : np.array([0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0]),\n        'M' : np.array([0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0]),\n        'L' : np.array([0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0]),\n        'N' : np.array([0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0]),\n        'Q' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0]),\n        'P' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0]),\n        'S' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0]),\n        'R' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0]),\n        'T' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0]),\n        'W' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0]),\n        'V' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0]),\n        'Y' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1]),\n        'X' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n    }\n    \n    return switch.get(arg)\n\ndef orthogonal_secondary(arg):\n    # H : 0, C : 1, E : 2\n    # C: C, B, T, S; H: H, G, I; E: E\n    switch = {\n        'H' : 0,                   \n        'C' : 1,\n        'E' : 2,\n    }\n    \n    return switch.get(arg)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.546597Z","iopub.status.idle":"2023-10-02T01:58:25.547363Z","shell.execute_reply.started":"2023-10-02T01:58:25.547119Z","shell.execute_reply":"2023-10-02T01:58:25.547144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for row in range(len(primary_split)):  \n    sequence = primary_split[row]\n    for col in range(len(sequence)):\n        #print(sequence[col])\n        sequence[col] = orthogonal_primary(sequence[col])\n        #print(sequence[col])","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.548542Z","iopub.status.idle":"2023-10-02T01:58:25.549314Z","shell.execute_reply.started":"2023-10-02T01:58:25.549058Z","shell.execute_reply":"2023-10-02T01:58:25.549083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for row in range(len(secondary_split)):  \n    sequenceS = secondary_split[row]\n    for col in range(len(sequenceS)):\n        sequenceS[col] = orthogonal_secondary(sequenceS[col])","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.556536Z","iopub.status.idle":"2023-10-02T01:58:25.558023Z","shell.execute_reply.started":"2023-10-02T01:58:25.557590Z","shell.execute_reply":"2023-10-02T01:58:25.557636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GNN","metadata":{}},{"cell_type":"markdown","source":"**graph_sum2**<br>\nthis function take input 2 node (amino acid character's onehot key) and return the sum of 2 node .<br>\n**graph_sum3**<br>\nthis function take input 3 node (amino acid character's onehot key) and return the sum of 3 node .","metadata":{}},{"cell_type":"code","source":"def graph_sum2(seq1,seq2):\n    result=[None]*len(seq1)\n    for col in range(len(seq1)):\n        result[col] =  seq1[col]+seq2[col]\n    return result\n\n\ndef graph_sum3(seq1,seq2,seq3):\n    result=[None]*len(seq1)\n    for col in range(len(seq1)):\n        result[col] =  seq1[col]+seq2[col]+seq3[col]\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.560038Z","iopub.status.idle":"2023-10-02T01:58:25.560590Z","shell.execute_reply.started":"2023-10-02T01:58:25.560347Z","shell.execute_reply":"2023-10-02T01:58:25.560371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Graph of primary structure**<br>\nThe primary structure is a linear string of character/amino acid(node) .<br>\nExample : ***ABBA***<br>\nIn Graph Neural Network , we take each node and sum the information value of it's adjacent node. As a result we find a new value for each node which is dependable for it's adjacent nodes .<br>\n![Untitled%20Diagram.jpg](attachment:Untitled%20Diagram.jpg)\nthe border node will use graph_sum2 function as it has only 1 adjacent node and the rest will use graph_sum3 function .","metadata":{}},{"cell_type":"code","source":"graph_input = copy.deepcopy(primary_split)\nfor row in range(len(primary_split)):\n    sequence = primary_split[row]\n    graph_input[row][0]=graph_sum2(sequence[0],sequence[1])\n    graph_input[row][len(sequence)-1]=graph_sum2(sequence[len(sequence)-1],sequence[len(sequence)-2])\n    for col in range(1,len(sequence)-1):\n        graph_input[row][col] = graph_sum3(sequence[col-1],sequence[col],sequence[col+1])\n        \ngraph_input[0]","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.563014Z","iopub.status.idle":"2023-10-02T01:58:25.563954Z","shell.execute_reply.started":"2023-10-02T01:58:25.563637Z","shell.execute_reply":"2023-10-02T01:58:25.563665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def targetY(data_list):\n    Y = []\n    for i in range(len(data_list)):\n        for j  in range(len(data_list[i])):\n            Y.append(data_list[i][j])\n    return Y","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.565611Z","iopub.status.idle":"2023-10-02T01:58:25.566536Z","shell.execute_reply.started":"2023-10-02T01:58:25.566258Z","shell.execute_reply":"2023-10-02T01:58:25.566285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_label = targetY(secondary_split)\nprint(len(y_label))\nprint(y_label[0:5])","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.568069Z","iopub.status.idle":"2023-10-02T01:58:25.568937Z","shell.execute_reply.started":"2023-10-02T01:58:25.568653Z","shell.execute_reply":"2023-10-02T01:58:25.568680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data feature is formed using the window_padding_data function. This function will accept the size of the sliding window and sequence of the primary structure of the protein. In this function features will be processed such as adding padding 0 at the beginning and end and taking the features of the results of windowing so that the output data can be directly trained on the SVM model","metadata":{}},{"cell_type":"code","source":"def window_padding_data(size, sequence):\n    num = int(size/2)\n    #print(\"initial :\",sequence[0])\n    #print(\"\")\n    zeros = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n    for i in range(len(sequence)):\n        for j in range(num):\n            sequence[i].append(zeros)\n            sequence[i].insert(0, zeros)\n            #print(sequence[i])\n            #print(\"\")\n            \n    X = []\n    temp = []\n\n    for k in range(len(sequence)):\n        #print(sequence[k])\n        for l in range(len(sequence[k])-(size-1)):\n            temp = sequence[k][l:l+size]\n           # print(temp)\n            X.append(temp)\n            temp = []\n\n    return X","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.570463Z","iopub.status.idle":"2023-10-02T01:58:25.571337Z","shell.execute_reply.started":"2023-10-02T01:58:25.571090Z","shell.execute_reply":"2023-10-02T01:58:25.571118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = window_padding_data(11,graph_input)\nprint(len(X))\nX[0]","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.572824Z","iopub.status.idle":"2023-10-02T01:58:25.573680Z","shell.execute_reply.started":"2023-10-02T01:58:25.573437Z","shell.execute_reply":"2023-10-02T01:58:25.573463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.set_printoptions(threshold=np.inf)\nX = np.array(X)\ny_label = np.array(y_label)\nX = X.reshape(len(X),11*20)\nprint(X[0:5])\nprint(\"X_train length :\",len(X))\nprint(\"y_label length :\",len(y_label))","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.575182Z","iopub.status.idle":"2023-10-02T01:58:25.576036Z","shell.execute_reply.started":"2023-10-02T01:58:25.575732Z","shell.execute_reply":"2023-10-02T01:58:25.575768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Convert the numpy array to a Pandas DataFrame\ntrain = pd.DataFrame(X)\ntrain['label'] = y_label.tolist()\ntrain.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.577490Z","iopub.status.idle":"2023-10-02T01:58:25.578349Z","shell.execute_reply.started":"2023-10-02T01:58:25.578109Z","shell.execute_reply":"2023-10-02T01:58:25.578134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.580196Z","iopub.status.idle":"2023-10-02T01:58:25.581122Z","shell.execute_reply.started":"2023-10-02T01:58:25.580789Z","shell.execute_reply":"2023-10-02T01:58:25.580852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"markdown","source":"### AutoGluon: Choosing the Model","metadata":{}},{"cell_type":"code","source":"!pip install autogluon","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.582564Z","iopub.status.idle":"2023-10-02T01:58:25.583475Z","shell.execute_reply.started":"2023-10-02T01:58:25.583223Z","shell.execute_reply":"2023-10-02T01:58:25.583247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.585419Z","iopub.status.idle":"2023-10-02T01:58:25.586176Z","shell.execute_reply.started":"2023-10-02T01:58:25.585941Z","shell.execute_reply":"2023-10-02T01:58:25.585965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from autogluon.tabular import TabularDataset, TabularPredictor\n\ntrain_data = TabularDataset(train)\n\nlabel = 'label'\nsave_path = 'model_ag'\npredictor = TabularPredictor(label=label, path=save_path, problem_type = 'multiclass', eval_metric=\"f1_macro\", sample_weight = 'balance_weight').fit(train_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.587536Z","iopub.status.idle":"2023-10-02T01:58:25.588339Z","shell.execute_reply.started":"2023-10-02T01:58:25.588075Z","shell.execute_reply":"2023-10-02T01:58:25.588100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictor.leaderboard()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.589682Z","iopub.status.idle":"2023-10-02T01:58:25.590399Z","shell.execute_reply.started":"2023-10-02T01:58:25.590163Z","shell.execute_reply":"2023-10-02T01:58:25.590187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictor = TabularPredictor.load(\"/kaggle/working/\"+save_path+'/')\npredictor.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.591563Z","iopub.status.idle":"2023-10-02T01:58:25.593062Z","shell.execute_reply.started":"2023-10-02T01:58:25.592764Z","shell.execute_reply":"2023-10-02T01:58:25.592790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Optimized Hyperparameter using Optuna","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\nimport sklearn\nimport optuna","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.594439Z","iopub.status.idle":"2023-10-02T01:58:25.595682Z","shell.execute_reply.started":"2023-10-02T01:58:25.595428Z","shell.execute_reply":"2023-10-02T01:58:25.595453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef objective(trial):\n#     iris = sklearn.datasets.load_iris()\n#     x, y = iris.data, iris.target\n    x = X\n    y = y_label\n    classifier_name = trial.suggest_categorical(\"classifier\", [\"SVC\", \"RandomForest\", \"lgb\"])\n\n    if classifier_name == \"SVC\":\n        svc_c = trial.suggest_float(\"svc_c\", 1e-10, 1e10, log=True)\n        classifier_obj = sklearn.svm.SVC(C=svc_c, gamma=\"auto\")\n    elif classifier_name == \"lgb\":\n        lgb_num_leaves = trial.suggest_int(\"lgb_num_leaves\", 31, 2**16-1, log=True)\n        classifier_obj = lgb.LGBMClassifier(num_leaves=lgb_num_leaves)\n    else:\n        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 2, 32, log=True)\n        classifier_obj = sklearn.ensemble.RandomForestClassifier(\n            max_depth=rf_max_depth, n_estimators=10\n        )\n\n    score = sklearn.model_selection.cross_val_score(classifier_obj, x, y, n_jobs=-1, cv=3)\n    accuracy = score.mean()\n    return accuracy\n\n# 3. Create a study object and optimize the objective function.\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=5)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.597236Z","iopub.status.idle":"2023-10-02T01:58:25.598627Z","shell.execute_reply.started":"2023-10-02T01:58:25.598364Z","shell.execute_reply":"2023-10-02T01:58:25.598390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.plot_optimization_history(study)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.599943Z","iopub.status.idle":"2023-10-02T01:58:25.601174Z","shell.execute_reply.started":"2023-10-02T01:58:25.600885Z","shell.execute_reply":"2023-10-02T01:58:25.600912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.plot_slice(study)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.603060Z","iopub.status.idle":"2023-10-02T01:58:25.603557Z","shell.execute_reply.started":"2023-10-02T01:58:25.603302Z","shell.execute_reply":"2023-10-02T01:58:25.603325Z"},"trusted":true},"execution_count":null,"outputs":[]}]}