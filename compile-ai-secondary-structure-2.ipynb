{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-02T01:52:25.459524Z","iopub.status.busy":"2023-10-02T01:52:25.459154Z","iopub.status.idle":"2023-10-02T01:52:25.469938Z","shell.execute_reply":"2023-10-02T01:52:25.468629Z","shell.execute_reply.started":"2023-10-02T01:52:25.459496Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["## Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T01:52:25.510068Z","iopub.status.busy":"2023-10-02T01:52:25.509329Z","iopub.status.idle":"2023-10-02T01:52:56.163610Z","shell.execute_reply":"2023-10-02T01:52:56.162133Z","shell.execute_reply.started":"2023-10-02T01:52:25.510034Z"},"trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","df = pd.read_csv('/kaggle/input/protein-secondary-structure/2018-06-06-ss.cleaned.csv')\n","print(df.shape)\n","\n","def seq2ngrams(seqs, n=3):\n","    return np.array([[seq[i:i+n] for i in range(len(seq))] for seq in seqs])\n","\n","df = df.head(5001)\n","maxlen_seq = 500\n","input_seqs, target_seqs = df[['seq', 'sst3']][(df.len <= maxlen_seq) & (~df.has_nonstd_aa)].values.T\n","input_grams = seq2ngrams(input_seqs)\n","print(len(input_seqs))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T01:52:56.165926Z","iopub.status.busy":"2023-10-02T01:52:56.165591Z","iopub.status.idle":"2023-10-02T01:52:56.623603Z","shell.execute_reply":"2023-10-02T01:52:56.622335Z","shell.execute_reply.started":"2023-10-02T01:52:56.165895Z"},"trusted":true},"outputs":[],"source":["\n","df.len.hist(bins=100)\n","print(df.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T01:52:56.625952Z","iopub.status.busy":"2023-10-02T01:52:56.625484Z","iopub.status.idle":"2023-10-02T01:52:56.661804Z","shell.execute_reply":"2023-10-02T01:52:56.660432Z","shell.execute_reply.started":"2023-10-02T01:52:56.625909Z"},"trusted":true},"outputs":[],"source":["from collections import defaultdict\n","# show proportion of each amino acid in a table\n","AA_counts = {'ss_2018': defaultdict(lambda: 0)}\n","# count the types for each dataset\n","for (seq, nonstd) in zip(df['seq'], df['has_nonstd_aa']):\n","    if not nonstd:\n","        for aa in set(seq):\n","            if aa != '*':\n","                AA_counts['ss_2018'][aa] += seq.count(aa)\n","\n","# order the amino acids by decreasing total abundance\n","total_aa = [sum([AA_counts[d][aa] for d in AA_counts.keys()]) for aa in AA_counts['ss_2018'].keys() ]\n","temp = sorted(total_aa, reverse = True)    \n","order = [total_aa.index(v) for v in temp]\n","aa_order = [list(AA_counts['ss_2018'].keys())[i] for i in order]\n","tbl_data = {'Amino Acid': aa_order,\n","            'ss_2018': [ round(AA_counts['ss_2018'][aa] / sum(AA_counts['ss_2018'].values()), 3) for aa in aa_order]}\n","pd.DataFrame(tbl_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T01:52:56.665399Z","iopub.status.busy":"2023-10-02T01:52:56.664327Z","iopub.status.idle":"2023-10-02T01:52:58.280021Z","shell.execute_reply":"2023-10-02T01:52:58.278645Z","shell.execute_reply.started":"2023-10-02T01:52:56.665363Z"},"trusted":true},"outputs":[],"source":["import seaborn as sns\n","dict_a = {'C':[],'H':[],'E':[]}\n","dict_f = {'C':[],'H':[],'E':[]}\n","dict_p = {'C':[],'H':[],'E':[]}\n","dict_s = {'C':[],'H':[],'E':[]}\n","\n","for se,sst in zip(df['seq'],df['sst3']):\n","    for s,ss in zip(se,sst):\n","        if s == 'A':\n","            if ss == 'C': dict_a['C'].append(1)\n","            elif ss == 'H': dict_a['H'].append(1)\n","            elif ss == 'E': dict_a['E'].append(1)\n","        elif s == 'F':        \n","            if ss == 'C': dict_f['C'].append(1)\n","            elif ss == 'H': dict_f['H'].append(1)\n","            elif ss == 'E': dict_f['E'].append(1)\n","        elif s == 'P':        \n","            if ss == 'C': dict_p['C'].append(1)\n","            elif ss == 'H': dict_p['H'].append(1)\n","            elif ss == 'E': dict_p['E'].append(1)\n","        elif s == 'S':        \n","            if ss == 'C': dict_s['C'].append(1)\n","            elif ss == 'H': dict_s['H'].append(1)\n","            elif ss == 'E': dict_s['E'].append(1)\n","                \n","                \n","for k in dict_a.keys(): dict_a[k] = sum(dict_a[k])\n","for k in dict_f.keys(): dict_f[k] = sum(dict_f[k])\n","for k in dict_p.keys(): dict_p[k] = sum(dict_p[k])\n","for k in dict_s.keys(): dict_s[k] = sum(dict_s[k])\n","print('dict_a:  ',dict_a)\n","print('dict_f:  ',dict_f)\n","print('dict_p:  ',dict_p)\n","print('dict_s:  ',dict_s)\n","\n","plt.figure(figsize=(14,4));\n","plt.subplot(1,2,1);\n","sns.barplot(x=list(dict_a.keys()),y=list(dict_a.values()),color='gray');\n","plt.title('Secondary Structure character counts for aminoacid A');\n","plt.subplot(1,2,2);\n","sns.barplot(x=list(dict_f.keys()),y=list(dict_f.values()),color='gray');\n","plt.title('Secondary Structure character counts for aminoacid F');\n","plt.figure(figsize=(14,4));\n","plt.subplot(1,2,1);\n","sns.barplot(x=list(dict_p.keys()),y=list(dict_p.values()),color='gray');\n","plt.title('Secondary Structure character counts for aminoacid P');\n","plt.subplot(1,2,2);\n","sns.barplot(x=list(dict_s.keys()),y=list(dict_s.values()),color='gray');\n","plt.title('Secondary Structure character counts for aminoacid S');"]},{"cell_type":"markdown","metadata":{},"source":["# Bi-LSTM to predict secondary structure"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T01:52:58.282895Z","iopub.status.busy":"2023-10-02T01:52:58.282204Z","iopub.status.idle":"2023-10-02T01:53:00.494162Z","shell.execute_reply":"2023-10-02T01:53:00.493015Z","shell.execute_reply.started":"2023-10-02T01:52:58.282791Z"},"trusted":true},"outputs":[],"source":["def seq2ngrams(seqs, n=3):\n","    return np.array([[seq[i:i+n] for i in range(len(seq))] for seq in seqs])\n","\n","maxlen_seq = 500\n","input_seqs, target_seqs = df[['seq', 'sst3']][(df.len <= maxlen_seq) & (~df.has_nonstd_aa)].values.T\n","input_grams = seq2ngrams(input_seqs)\n","print(len(input_seqs))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T01:53:00.496686Z","iopub.status.busy":"2023-10-02T01:53:00.495989Z","iopub.status.idle":"2023-10-02T01:53:09.876449Z","shell.execute_reply":"2023-10-02T01:53:09.875035Z","shell.execute_reply.started":"2023-10-02T01:53:00.496641Z"},"trusted":true},"outputs":[],"source":["from keras.preprocessing import text\n","from keras.utils.data_utils import pad_sequences \n","from keras.preprocessing.text import Tokenizer\n","from keras.utils import to_categorical\n","\n","tokenizer_encoder = Tokenizer()\n","tokenizer_encoder.fit_on_texts(input_grams)\n","input_data = tokenizer_encoder.texts_to_sequences(input_grams)\n","input_data = pad_sequences(input_data, maxlen=maxlen_seq, padding='post')\n","\n","tokenizer_decoder = Tokenizer(char_level=True)\n","tokenizer_decoder.fit_on_texts(target_seqs)\n","target_data = tokenizer_decoder.texts_to_sequences(target_seqs)\n","target_data = pad_sequences(target_data, maxlen=maxlen_seq, padding='post')\n","target_data = to_categorical(target_data)\n","input_data.shape, target_data.shape"]},{"cell_type":"markdown","metadata":{},"source":["## Building model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T01:53:09.879799Z","iopub.status.busy":"2023-10-02T01:53:09.878541Z","iopub.status.idle":"2023-10-02T01:53:10.948256Z","shell.execute_reply":"2023-10-02T01:53:10.946939Z","shell.execute_reply.started":"2023-10-02T01:53:09.879753Z"},"trusted":true},"outputs":[],"source":["from keras.models import Model\n","from tensorflow.keras.layers import Input\n","from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Bidirectional\n","\n","n_words = len(tokenizer_encoder.word_index) + 1\n","n_tags = len(tokenizer_decoder.word_index) + 1\n","print(n_words, n_tags)\n","\n","input = Input(shape=(maxlen_seq))\n","x = Embedding(input_dim=n_words, output_dim=128, input_length=maxlen_seq)(input)\n","x = Bidirectional(LSTM(units=64, return_sequences=True, recurrent_dropout=0.1))(x)\n","y = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(x)\n","model = Model(input, y)\n","model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["## Train and Evaluate Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T01:53:10.950432Z","iopub.status.busy":"2023-10-02T01:53:10.950029Z","iopub.status.idle":"2023-10-02T01:58:08.484898Z","shell.execute_reply":"2023-10-02T01:58:08.483698Z","shell.execute_reply.started":"2023-10-02T01:53:10.950400Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from keras.metrics import categorical_accuracy\n","from keras import backend  as K\n","import tensorflow as tf\n","\n","def q3_acc(y_true, y_pred):\n","    y = tf.argmax(y_true, axis=-1)\n","    y_ = tf.argmax(y_pred, axis=-1)\n","    mask = tf.greater(y, 0)\n","    return K.cast(K.equal(tf.boolean_mask(y, mask), tf.boolean_mask(y_, mask)), K.floatx())\n","\n","model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", q3_acc])\n","\n","X_train, X_test, y_train, y_test = train_test_split(input_data, target_data, test_size=.4, random_state=0)\n","seq_train, seq_test, target_train, target_test = train_test_split(input_seqs, target_seqs, test_size=.4, random_state=0)\n","\n","history = model.fit(X_train, y_train, batch_size=128, epochs=20, validation_data=(X_test, y_test), verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T01:58:08.488011Z","iopub.status.busy":"2023-10-02T01:58:08.486830Z","iopub.status.idle":"2023-10-02T01:58:09.227031Z","shell.execute_reply":"2023-10-02T01:58:09.225929Z","shell.execute_reply.started":"2023-10-02T01:58:08.487963Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","# Plot training history\n","def viz_hist(history):\n","    plt.figure(figsize=(12, 6))\n","\n","    # Plot training & validation loss values\n","    plt.subplot(1, 3, 1)\n","    plt.plot(history.history['loss'], label='Training Loss')\n","    plt.plot(history.history['val_loss'], label='Validation Loss')\n","    plt.title('Model Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","\n","    # Plot training & validation accuracy values\n","    plt.subplot(1, 3, 2)\n","    plt.plot(history.history['accuracy'], label='Training Accuracy')\n","    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","    plt.title('Model Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","\n","    # Plot training & validation accuracy values\n","    plt.subplot(1, 3, 3)\n","    plt.plot(history.history['q3_acc'], label='Training Q3 Accuracy')\n","    plt.plot(history.history['val_q3_acc'], label='Validation Q3 Accuracy')\n","    plt.title('Model Q3 Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","    plt.show()\n","    \n","viz_hist(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T01:58:09.231529Z","iopub.status.busy":"2023-10-02T01:58:09.231236Z","iopub.status.idle":"2023-10-02T01:58:11.131820Z","shell.execute_reply":"2023-10-02T01:58:11.130356Z","shell.execute_reply.started":"2023-10-02T01:58:09.231504Z"},"trusted":true},"outputs":[],"source":["def onehot_to_seq(oh_seq, index):\n","    s = ''\n","    for o in oh_seq:\n","        i = np.argmax(o)\n","        if i != 0:\n","            s += index[i]\n","        else:\n","            break\n","    return s\n","\n","def plot_results(x, y, y_):\n","    print(\"---\")\n","    print(\"Input: \" + str(x))\n","    print(\"Target: \" + str(onehot_to_seq(y, revsere_decoder_index).upper()))\n","    print(\"Result: \" + str(onehot_to_seq(y_, revsere_decoder_index).upper()))\n","    fig = plt.figure(figsize=(10,2))\n","    plt.imshow(y.T, cmap='Blues')\n","    plt.imshow(y_.T, cmap='Reds', alpha=.5)\n","    plt.yticks(range(4), [' '] + [revsere_decoder_index[i+1].upper() for i in range(3)])\n","    plt.show()\n","    \n","revsere_decoder_index = {value:key for key,value in tokenizer_decoder.word_index.items()}\n","revsere_encoder_index = {value:key for key,value in tokenizer_encoder.word_index.items()}\n","\n","N=3\n","y_train_pred = model.predict(X_train[:N])\n","y_test_pred = model.predict(X_test[:N])\n","print('training')\n","for i in range(N):\n","    plot_results(seq_train[i], y_train[i], y_train_pred[i])\n","print('testing')\n","for i in range(N):\n","    plot_results(seq_test[i], y_test[i], y_test_pred[i])"]},{"cell_type":"markdown","metadata":{},"source":["## Optimizing Hyperparameter"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T01:58:11.133536Z","iopub.status.busy":"2023-10-02T01:58:11.133222Z","iopub.status.idle":"2023-10-02T01:58:23.558359Z","shell.execute_reply":"2023-10-02T01:58:23.556161Z","shell.execute_reply.started":"2023-10-02T01:58:11.133510Z"},"trusted":true},"outputs":[],"source":["!pip install optuna"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T03:22:21.644565Z","iopub.status.busy":"2023-10-02T03:22:21.644144Z","iopub.status.idle":"2023-10-02T03:22:21.654248Z","shell.execute_reply":"2023-10-02T03:22:21.652822Z","shell.execute_reply.started":"2023-10-02T03:22:21.644521Z"},"trusted":true},"outputs":[],"source":["def objective(trial):\n","    # Get the hyperparameters\n","    dropout = trial.suggest_float('dropout', 0.1, 0.2)\n","    activation = trial.suggest_categorical('activation', ['relu', 'tanh', 'softmax'])\n","\n","    # Create the BiLSTM model\n","    input = Input(shape=(maxlen_seq))\n","    x = Embedding(input_dim=n_words, output_dim=128, input_length=maxlen_seq)(input)\n","    x = Bidirectional(LSTM(units=64, return_sequences=True, recurrent_dropout=dropout))(x)\n","    y = TimeDistributed(Dense(n_tags, activation=activation))(x)\n","    model = Model(input, y)\n","    \n","    # Compile the model\n","    model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", q3_acc])\n","\n","\n","    # Train the model\n","    history = model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_test, y_test), verbose=1)\n","    #viz \n","    viz_hist(history)\n","#     y_res = model.predict(X_test)\n","#     return q3_acc(y_test,y_res)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T03:22:26.156821Z","iopub.status.busy":"2023-10-02T03:22:26.156184Z"},"trusted":true},"outputs":[],"source":["import optuna\n","study = optuna.create_study()\n","study.optimize(objective, n_trials=10)\n","# best_dropout = study.best_params['dropout']\n","# best_activation = study.best_params['activation']"]},{"cell_type":"markdown","metadata":{},"source":["# ML to predict secondary structure"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.531233Z","iopub.status.idle":"2023-10-02T01:58:25.531645Z","shell.execute_reply":"2023-10-02T01:58:25.531470Z","shell.execute_reply.started":"2023-10-02T01:58:25.531452Z"},"trusted":true},"outputs":[],"source":["import numpy as np                                     # linear algebra\n","import pandas as pd                                    # data processing, CSV file I/O (e.g. pd.read_csv)\n","import copy                                            #to copy list\n","from sklearn.model_selection import train_test_split   #to split dataset into train and test set\n","from sklearn.svm import SVC                            #to create svc instance\n","from sklearn.metrics import classification_report      #to create report for precision,recall,f1-score,accuracy\n","from sklearn import metrics                            #to get accuracy\n","from sklearn.model_selection import GridSearchCV       #to optimise the hyper-parameter\n","import math"]},{"cell_type":"markdown","metadata":{},"source":["## Pre processing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.535591Z","iopub.status.idle":"2023-10-02T01:58:25.536073Z","shell.execute_reply":"2023-10-02T01:58:25.535822Z","shell.execute_reply.started":"2023-10-02T01:58:25.535807Z"},"trusted":true},"outputs":[],"source":["#dataset 1\n","maxlen_seq = 128\n","input_seqs, target_seqs = df[['seq', 'sst3']][(df.len <= maxlen_seq) & (~df.has_nonstd_aa)].values.T\n","input_seqs, target_seqs = df[['seq', 'sst3']][(~df.has_nonstd_aa)].values.T\n","# input_grams = seq2ngrams(input_seqs)\n","print(input_seqs[0:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.537721Z","iopub.status.idle":"2023-10-02T01:58:25.538496Z","shell.execute_reply":"2023-10-02T01:58:25.538266Z","shell.execute_reply.started":"2023-10-02T01:58:25.538240Z"},"trusted":true},"outputs":[],"source":["inputSeqs=[]\n","targetSeqs=[]\n","for i in range(input_seqs.size):\n","    j=0\n","    while(j<len(input_seqs[i])/128):\n","        start = j*128\n","        end = start+128\n","        inputSeqs.append(input_seqs[i][start:end])\n","        targetSeqs.append(target_seqs[i][start:end])\n","        j+=1\n","        \n","print(len(targetSeqs))\n","print(len(inputSeqs))"]},{"cell_type":"markdown","metadata":{},"source":["**Looking for incomplete data**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.539655Z","iopub.status.idle":"2023-10-02T01:58:25.540311Z","shell.execute_reply":"2023-10-02T01:58:25.540118Z","shell.execute_reply.started":"2023-10-02T01:58:25.540095Z"},"trusted":true},"outputs":[],"source":["for row in range(len(targetSeqs)):\n","    secondary_lenth = len(targetSeqs[row])\n","    primary_lenth = len(inputSeqs[row])\n","    \n","    if(secondary_lenth != primary_lenth):\n","        print(\"(\",row,\") Secondary_Structure ->\", targetSeqs[row],\" Primary_Structure -> \",inputSeqs[row])\n","    \n","print(len(inputSeqs))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.541320Z","iopub.status.idle":"2023-10-02T01:58:25.541957Z","shell.execute_reply":"2023-10-02T01:58:25.541730Z","shell.execute_reply.started":"2023-10-02T01:58:25.541709Z"},"trusted":true},"outputs":[],"source":["secondary_count = 0\n","primary_count = 0\n","dataCheck = \"ACEDGFIHKMLNQPSRTWVY\"\n","index=[]\n","for row in range(len(targetSeqs)):\n","    secondary_lenth = len(targetSeqs[row])\n","    primary_lenth = len(inputSeqs[row])\n","    secondary_count = secondary_count + secondary_lenth\n","    primary_count = primary_count + primary_lenth\n","    if(secondary_lenth != primary_lenth):\n","        print(\"(\",row,\") Secondary_Structure ->\", targetSeqs[row],\" Primary_Structure -> \",inputSeqs[row])\n","    for col in range(len(inputSeqs[row])):\n","        #print(\"before :\",inputSeqs[row][col])\n","        if len(inputSeqs[row])<2:\n","            index.append(row)\n","        if dataCheck.find(inputSeqs[row][col])==-1:\n","            #print(\"after :\",inputSeqs[row][col])\n","            index.append(row)\n","           # print(\"Row : \"+str(row)+\"have been deleted for having unknown data\")\n","            break\n","            \n","\n","inputSeqs =np.delete(inputSeqs,index)\n","targetSeqs =np.delete(targetSeqs,index)\n","        \n","print(\"count of secondary structure : \",secondary_count)\n","print(\"count of primary structure : \",primary_count)\n","print(\"size of primary structure : \",len(inputSeqs))"]},{"cell_type":"markdown","metadata":{},"source":["**Orthogonal Encoding - Target Labeling**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.543185Z","iopub.status.idle":"2023-10-02T01:58:25.543897Z","shell.execute_reply":"2023-10-02T01:58:25.543655Z","shell.execute_reply.started":"2023-10-02T01:58:25.543620Z"},"trusted":true},"outputs":[],"source":["def split(sequence): \n","    return [char for char in sequence]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.544928Z","iopub.status.idle":"2023-10-02T01:58:25.545530Z","shell.execute_reply":"2023-10-02T01:58:25.545351Z","shell.execute_reply.started":"2023-10-02T01:58:25.545329Z"},"trusted":true},"outputs":[],"source":["primary_split = []\n","secondary_split = []\n","for row in range(int(len(targetSeqs)/1)):\n","    primary_split.append(split(inputSeqs[row]))\n","    secondary_split.append(split(targetSeqs[row]))\n","    \n","print(len(primary_split))"]},{"cell_type":"markdown","metadata":{},"source":["The results of the split primary and secondary structure of the protein are then converted into orthogonal encoding and target labeling. A switch case snippet for each amino acid in the primary structure of a protein as follows .<br>\n","Secondary structure character represent ->\n","1. H= α-helix\n","2. C= Loops and irregular elements\n","3. E= β-strand\n","4. B= β-bridge\n","5. G= 3-helix\n","6. I= π-helix\n","7. T= Turn\n","8. S= Bend"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.546597Z","iopub.status.idle":"2023-10-02T01:58:25.547363Z","shell.execute_reply":"2023-10-02T01:58:25.547144Z","shell.execute_reply.started":"2023-10-02T01:58:25.547119Z"},"trusted":true},"outputs":[],"source":["def orthogonal_primary(arg):\n","    switch = {\n","        'A' : np.array([1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]),  # 20 amino acids\n","        'C' : np.array([0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]),\n","        'E' : np.array([0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]),\n","        'D' : np.array([0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]),\n","        'G' : np.array([0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]),\n","        'F' : np.array([0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]),\n","        'I' : np.array([0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0]),\n","        'H' : np.array([0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0]),\n","        'K' : np.array([0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0]),\n","        'M' : np.array([0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0]),\n","        'L' : np.array([0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0]),\n","        'N' : np.array([0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0]),\n","        'Q' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0]),\n","        'P' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0]),\n","        'S' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0]),\n","        'R' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0]),\n","        'T' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0]),\n","        'W' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0]),\n","        'V' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0]),\n","        'Y' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1]),\n","        'X' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n","    }\n","    \n","    return switch.get(arg)\n","\n","def orthogonal_secondary(arg):\n","    # H : 0, C : 1, E : 2\n","    # C: C, B, T, S; H: H, G, I; E: E\n","    switch = {\n","        'H' : 0,                   \n","        'C' : 1,\n","        'E' : 2,\n","    }\n","    \n","    return switch.get(arg)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.548542Z","iopub.status.idle":"2023-10-02T01:58:25.549314Z","shell.execute_reply":"2023-10-02T01:58:25.549083Z","shell.execute_reply.started":"2023-10-02T01:58:25.549058Z"},"trusted":true},"outputs":[],"source":["for row in range(len(primary_split)):  \n","    sequence = primary_split[row]\n","    for col in range(len(sequence)):\n","        #print(sequence[col])\n","        sequence[col] = orthogonal_primary(sequence[col])\n","        #print(sequence[col])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.556536Z","iopub.status.idle":"2023-10-02T01:58:25.558023Z","shell.execute_reply":"2023-10-02T01:58:25.557636Z","shell.execute_reply.started":"2023-10-02T01:58:25.557590Z"},"trusted":true},"outputs":[],"source":["for row in range(len(secondary_split)):  \n","    sequenceS = secondary_split[row]\n","    for col in range(len(sequenceS)):\n","        sequenceS[col] = orthogonal_secondary(sequenceS[col])"]},{"cell_type":"markdown","metadata":{},"source":["## GNN"]},{"cell_type":"markdown","metadata":{},"source":["**graph_sum2**<br>\n","this function take input 2 node (amino acid character's onehot key) and return the sum of 2 node .<br>\n","**graph_sum3**<br>\n","this function take input 3 node (amino acid character's onehot key) and return the sum of 3 node ."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.560038Z","iopub.status.idle":"2023-10-02T01:58:25.560590Z","shell.execute_reply":"2023-10-02T01:58:25.560371Z","shell.execute_reply.started":"2023-10-02T01:58:25.560347Z"},"trusted":true},"outputs":[],"source":["def graph_sum2(seq1,seq2):\n","    result=[None]*len(seq1)\n","    for col in range(len(seq1)):\n","        result[col] =  seq1[col]+seq2[col]\n","    return result\n","\n","\n","def graph_sum3(seq1,seq2,seq3):\n","    result=[None]*len(seq1)\n","    for col in range(len(seq1)):\n","        result[col] =  seq1[col]+seq2[col]+seq3[col]\n","    return result"]},{"cell_type":"markdown","metadata":{},"source":["**Graph of primary structure**<br>\n","The primary structure is a linear string of character/amino acid(node) .<br>\n","Example : ***ABBA***<br>\n","In Graph Neural Network , we take each node and sum the information value of it's adjacent node. As a result we find a new value for each node which is dependable for it's adjacent nodes .<br>\n","the border node will use graph_sum2 function as it has only 1 adjacent node and the rest will use graph_sum3 function ."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.563014Z","iopub.status.idle":"2023-10-02T01:58:25.563954Z","shell.execute_reply":"2023-10-02T01:58:25.563665Z","shell.execute_reply.started":"2023-10-02T01:58:25.563637Z"},"trusted":true},"outputs":[],"source":["graph_input = copy.deepcopy(primary_split)\n","for row in range(len(primary_split)):\n","    sequence = primary_split[row]\n","    graph_input[row][0]=graph_sum2(sequence[0],sequence[1])\n","    graph_input[row][len(sequence)-1]=graph_sum2(sequence[len(sequence)-1],sequence[len(sequence)-2])\n","    for col in range(1,len(sequence)-1):\n","        graph_input[row][col] = graph_sum3(sequence[col-1],sequence[col],sequence[col+1])\n","        \n","graph_input[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.565611Z","iopub.status.idle":"2023-10-02T01:58:25.566536Z","shell.execute_reply":"2023-10-02T01:58:25.566285Z","shell.execute_reply.started":"2023-10-02T01:58:25.566258Z"},"trusted":true},"outputs":[],"source":["def targetY(data_list):\n","    Y = []\n","    for i in range(len(data_list)):\n","        for j  in range(len(data_list[i])):\n","            Y.append(data_list[i][j])\n","    return Y"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.568069Z","iopub.status.idle":"2023-10-02T01:58:25.568937Z","shell.execute_reply":"2023-10-02T01:58:25.568680Z","shell.execute_reply.started":"2023-10-02T01:58:25.568653Z"},"trusted":true},"outputs":[],"source":["y_label = targetY(secondary_split)\n","print(len(y_label))\n","print(y_label[0:5])"]},{"cell_type":"markdown","metadata":{},"source":["The data feature is formed using the window_padding_data function. This function will accept the size of the sliding window and sequence of the primary structure of the protein. In this function features will be processed such as adding padding 0 at the beginning and end and taking the features of the results of windowing so that the output data can be directly trained on the SVM model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.570463Z","iopub.status.idle":"2023-10-02T01:58:25.571337Z","shell.execute_reply":"2023-10-02T01:58:25.571118Z","shell.execute_reply.started":"2023-10-02T01:58:25.571090Z"},"trusted":true},"outputs":[],"source":["def window_padding_data(size, sequence):\n","    num = int(size/2)\n","    #print(\"initial :\",sequence[0])\n","    #print(\"\")\n","    zeros = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","    for i in range(len(sequence)):\n","        for j in range(num):\n","            sequence[i].append(zeros)\n","            sequence[i].insert(0, zeros)\n","            #print(sequence[i])\n","            #print(\"\")\n","            \n","    X = []\n","    temp = []\n","\n","    for k in range(len(sequence)):\n","        #print(sequence[k])\n","        for l in range(len(sequence[k])-(size-1)):\n","            temp = sequence[k][l:l+size]\n","           # print(temp)\n","            X.append(temp)\n","            temp = []\n","\n","    return X"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.572824Z","iopub.status.idle":"2023-10-02T01:58:25.573680Z","shell.execute_reply":"2023-10-02T01:58:25.573463Z","shell.execute_reply.started":"2023-10-02T01:58:25.573437Z"},"trusted":true},"outputs":[],"source":["X = window_padding_data(11,graph_input)\n","print(len(X))\n","X[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.575182Z","iopub.status.idle":"2023-10-02T01:58:25.576036Z","shell.execute_reply":"2023-10-02T01:58:25.575768Z","shell.execute_reply.started":"2023-10-02T01:58:25.575732Z"},"trusted":true},"outputs":[],"source":["np.set_printoptions(threshold=np.inf)\n","X = np.array(X)\n","y_label = np.array(y_label)\n","X = X.reshape(len(X),11*20)\n","print(X[0:5])\n","print(\"X_train length :\",len(X))\n","print(\"y_label length :\",len(y_label))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.577490Z","iopub.status.idle":"2023-10-02T01:58:25.578349Z","shell.execute_reply":"2023-10-02T01:58:25.578134Z","shell.execute_reply.started":"2023-10-02T01:58:25.578109Z"},"trusted":true},"outputs":[],"source":["\n","# Convert the numpy array to a Pandas DataFrame\n","train = pd.DataFrame(X)\n","train['label'] = y_label.tolist()\n","train.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.580196Z","iopub.status.idle":"2023-10-02T01:58:25.581122Z","shell.execute_reply":"2023-10-02T01:58:25.580852Z","shell.execute_reply.started":"2023-10-02T01:58:25.580789Z"},"trusted":true},"outputs":[],"source":["train['label'].value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"markdown","metadata":{},"source":["### AutoGluon: Choosing the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.582564Z","iopub.status.idle":"2023-10-02T01:58:25.583475Z","shell.execute_reply":"2023-10-02T01:58:25.583247Z","shell.execute_reply.started":"2023-10-02T01:58:25.583223Z"},"trusted":true},"outputs":[],"source":["!pip install autogluon"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.585419Z","iopub.status.idle":"2023-10-02T01:58:25.586176Z","shell.execute_reply":"2023-10-02T01:58:25.585965Z","shell.execute_reply.started":"2023-10-02T01:58:25.585941Z"},"trusted":true},"outputs":[],"source":["import gc\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.587536Z","iopub.status.idle":"2023-10-02T01:58:25.588339Z","shell.execute_reply":"2023-10-02T01:58:25.588100Z","shell.execute_reply.started":"2023-10-02T01:58:25.588075Z"},"trusted":true},"outputs":[],"source":["from autogluon.tabular import TabularDataset, TabularPredictor\n","\n","train_data = TabularDataset(train)\n","\n","label = 'label'\n","save_path = 'model_ag'\n","predictor = TabularPredictor(label=label, path=save_path, problem_type = 'multiclass', eval_metric=\"f1_macro\", sample_weight = 'balance_weight').fit(train_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.589682Z","iopub.status.idle":"2023-10-02T01:58:25.590399Z","shell.execute_reply":"2023-10-02T01:58:25.590187Z","shell.execute_reply.started":"2023-10-02T01:58:25.590163Z"},"trusted":true},"outputs":[],"source":["predictor.leaderboard()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.591563Z","iopub.status.idle":"2023-10-02T01:58:25.593062Z","shell.execute_reply":"2023-10-02T01:58:25.592790Z","shell.execute_reply.started":"2023-10-02T01:58:25.592764Z"},"trusted":true},"outputs":[],"source":["predictor = TabularPredictor.load(\"/kaggle/working/\"+save_path+'/')\n","predictor.info()"]},{"cell_type":"markdown","metadata":{},"source":["### Optimized Hyperparameter using Optuna"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.594439Z","iopub.status.idle":"2023-10-02T01:58:25.595682Z","shell.execute_reply":"2023-10-02T01:58:25.595453Z","shell.execute_reply.started":"2023-10-02T01:58:25.595428Z"},"trusted":true},"outputs":[],"source":["import lightgbm as lgb\n","import sklearn\n","import optuna"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.597236Z","iopub.status.idle":"2023-10-02T01:58:25.598627Z","shell.execute_reply":"2023-10-02T01:58:25.598390Z","shell.execute_reply.started":"2023-10-02T01:58:25.598364Z"},"trusted":true},"outputs":[],"source":["\n","def objective(trial):\n","#     iris = sklearn.datasets.load_iris()\n","#     x, y = iris.data, iris.target\n","    x = X\n","    y = y_label\n","    classifier_name = trial.suggest_categorical(\"classifier\", [\"SVC\", \"RandomForest\", \"lgb\"])\n","\n","    if classifier_name == \"SVC\":\n","        svc_c = trial.suggest_float(\"svc_c\", 1e-10, 1e10, log=True)\n","        classifier_obj = sklearn.svm.SVC(C=svc_c, gamma=\"auto\")\n","    elif classifier_name == \"lgb\":\n","        lgb_num_leaves = trial.suggest_int(\"lgb_num_leaves\", 31, 2**16-1, log=True)\n","        classifier_obj = lgb.LGBMClassifier(num_leaves=lgb_num_leaves)\n","    else:\n","        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 2, 32, log=True)\n","        classifier_obj = sklearn.ensemble.RandomForestClassifier(\n","            max_depth=rf_max_depth, n_estimators=10\n","        )\n","\n","    score = sklearn.model_selection.cross_val_score(classifier_obj, x, y, n_jobs=-1, cv=3)\n","    accuracy = score.mean()\n","    return accuracy\n","\n","# 3. Create a study object and optimize the objective function.\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.599943Z","iopub.status.idle":"2023-10-02T01:58:25.601174Z","shell.execute_reply":"2023-10-02T01:58:25.600912Z","shell.execute_reply.started":"2023-10-02T01:58:25.600885Z"},"trusted":true},"outputs":[],"source":["optuna.visualization.plot_optimization_history(study)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-02T01:58:25.603060Z","iopub.status.idle":"2023-10-02T01:58:25.603557Z","shell.execute_reply":"2023-10-02T01:58:25.603325Z","shell.execute_reply.started":"2023-10-02T01:58:25.603302Z"},"trusted":true},"outputs":[],"source":["optuna.visualization.plot_slice(study)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
